import os
import re
import argparse
import csv
from pathlib import Path
from urllib.parse import urlparse

class SensitiveInfoScanner:
    def __init__(self):
        # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        self.supported_extensions = {
            '.java', '.js', '.jsx', '.ts', '.tsx',  # Javaå’ŒJavaScript/TypeScript
            '.php', '.py', '.rb', '.go', '.rs',     # å…¶ä»–åç«¯è¯­è¨€
            '.cpp', '.c', '.h', '.hpp',             # C/C++
            '.cs', '.vb',                           # .NET
            '.swift', '.m', '.mm',                  # iOS/macOS
            '.kt', '.kts',                          # Kotlin
            '.scala', '.clj',                       # Scala/Clojure
            '.sh', '.bash', '.zsh',                 # Shellè„šæœ¬
            '.ps1', '.bat', '.cmd',                 # Windowsè„šæœ¬
            '.sql', '.pl', '.r',                    # æ•°æ®åº“å’Œè„šæœ¬
            '.html', '.htm', '.xml', '.json',       # æ ‡è®°è¯­è¨€
            '.yml', '.yaml', '.toml', '.ini',       # é…ç½®æ–‡ä»¶
            '.properties', '.cfg', '.conf',
            '.txt', '.md', '.rst',                  # æ–‡æœ¬æ–‡ä»¶
            '.gradle', '.groovy',                   # æ„å»ºè„šæœ¬
            '.dockerfile', '.docker',               # Dockeræ–‡ä»¶
        }
        
        # æ›´å…¨é¢çš„æ•æ„Ÿä¿¡æ¯æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.patterns = {
            'ç¡¬ç¼–ç å¯†ç ': [
                r'password\s*[=:]\s*["\']([^"\']{4,})["\']',
                r'pwd\s*[=:]\s*["\']([^"\']{4,})["\']',
                r'passwd\s*[=:]\s*["\']([^"\']{4,})["\']',
                r'\.password\s*\(\s*["\']([^"\']{4,})["\']',
                r'\.pwd\s*\(\s*["\']([^"\']{4,})["\']',
                r'new\s+PasswordAuthentication\s*\(\s*["\'][^"\']*["\']\s*,\s*["\']([^"\']{4,})["\']\s*\)',
                r'"password"\s*:\s*"([^"]{4,})"',
                r"'password'\s*:\s*'([^']{4,})'"
            ],
            'APIå¯†é’¥/AppID': [
                r'api[_-]?key\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'apikey\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'\.apiKey\s*\(\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'appId\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'\.appId\s*\(\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'appid\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'\.appid\s*\(\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'sk-[a-zA-Z0-9]{20,}',  # OpenAIå¯†é’¥æ ¼å¼
                r'AKIA[0-9A-Z]{16}',  # AWSå¯†é’¥æ ¼å¼
                r'gh[pousr]_[A-Za-z0-9_]{36}',  # GitHubå¯†é’¥æ ¼å¼
                r'"api_key"\s*:\s*"([^"]{16,})"',
                r"'api_key'\s*:\s*'([^']{16,})'"
            ],
            'Secretå¯†é’¥': [
                r'secret[_-]?key\s*[=:]\s*["\']([^"\']{8,})["\']',
                r'\.secretKey\s*\(\s*["\']([^"\']{8,})["\']',
                r'secret\s*[=:]\s*["\']([^"\']{8,})["\']',
                r'\.secret\s*\(\s*["\']([^"\']{8,})["\']',
                r'client[_-]?secret\s*[=:]\s*["\']([^"\']{8,})["\']',
                r'\.clientSecret\s*\(\s*["\']([^"\']{8,})["\']',
                r'"secret"\s*:\s*"([^"]{8,})"',
                r"'secret'\s*:\s*'([^']{8,})'"
            ],
            'è®¿é—®ä»¤ç‰Œ': [
                r'access[_-]?token\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'token\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'\.accessToken\s*\(\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'\.token\s*\(\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'bearer\s+[a-zA-Z0-9_-]{20,}',  # Bearer token
                r'"token"\s*:\s*"([^"]{16,})"',
                r"'token'\s*:\s*'([^']{16,})'",
                r'"access_token"\s*:\s*"([^"]{16,})"',
                r"'access_token'\s*:\s*'([^']{16,})'"
            ],
            'æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²': [
                r'jdbc:(?:mysql|postgresql|oracle):(?:[^\s"\']*://)?[^\s"\']*:[0-9]+/[^\s"\']*',
                r'mongodb(?:\\+srv)?://[^\s"\']+',
                r'redis://[^\s"\']+',
                r'DataSource[^;]*=[^;]*;',
                r'mysql://[^\s"\']+',
                r'postgresql://[^\s"\']+',
                r'postgres://[^\s"\']+',
                r'"connectionString"\s*:\s*"[^"]*(?:jdbc|mongodb|redis|mysql|postgres)[^"]*"',
                r"'connectionString'\s*:\s*'[^']*(?:jdbc|mongodb|redis|mysql|postgres)[^']*'"
            ],
            'åŠ å¯†å¯†é’¥': [
                r'encryption[_-]?key\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'aes[_-]?key\s*[=:]\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'\.encryptionKey\s*\(\s*["\']([a-zA-Z0-9]{16,})["\']',
                r'"encryption_key"\s*:\s*"([^"]{16,})"',
                r"'encryption_key'\s*:\s*'([^']{16,})'"
            ],
            'é‚®ç®±é…ç½®': [
                r'mail\.(?:smtp\.)?password\s*[=:]\s*["\']([^"\']{4,})["\']',
                r'email\.password\s*[=:]\s*["\']([^"\']{4,})["\']',
                r'\.mailPassword\s*\(\s*["\']([^"\']{4,})["\']',
                r'smtp_password\s*[=:]\s*["\']([^"\']{4,})["\']',
                r'"smtp_password"\s*:\s*"([^"]{4,})"',
                r"'smtp_password'\s*:\s*'([^']{4,})'"
            ],
            'IPåœ°å€': [
                r'\b(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b',
                r'ip\s*[=:]\s*["\']((?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))["\']',
                r'host\s*[=:]\s*["\']((?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))["\']',
            ],
            'åŸŸå': [
                r'\b(?:https?://)?(?:www\.)?([a-zA-Z0-9](?:[a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}(?::[0-9]{1,5})?\b',
                r'domain\s*[=:]\s*["\']([a-zA-Z0-9](?:[a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}["\']',
                r'hostname\s*[=:]\s*["\']([a-zA-Z0-9](?:[a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}["\']',
                r'baseUrl\s*[=:]\s*["\'](?:https?://)?([a-zA-Z0-9](?:[a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}["\']',
            ],
            'URLé“¾æ¥': [
                r'https?://[^\s"\']+',
                r'ftp://[^\s"\']+',
                r'ws://[^\s"\']+',
                r'wss://[^\s"\']+',
                r'url\s*[=:]\s*["\'](https?://[^"\']+)["\']',
                r'endpoint\s*[=:]\s*["\'](https?://[^"\']+)["\']',
                r'baseUrl\s*[=:]\s*["\'](https?://[^"\']+)["\']',
                r'server\s*[=:]\s*["\'](https?://[^"\']+)["\']',
            ],
            'é…ç½®æ–‡ä»¶æ•æ„Ÿä¿¡æ¯': [
                r'DATABASE_URL\s*[=:]\s*["\']([^"\']+)["\']',
                r'REDIS_URL\s*[=:]\s*["\']([^"\']+)["\']',
                r'AWS_ACCESS_KEY_ID\s*[=:]\s*["\']([^"\']+)["\']',
                r'AWS_SECRET_ACCESS_KEY\s*[=:]\s*["\']([^"\']+)["\']',
                r'STRIPE_SECRET_KEY\s*[=:]\s*["\']([^"\']+)["\']',
                r'STRIPE_PUBLISHABLE_KEY\s*[=:]\s*["\']([^"\']+)["\']',
                r'FACEBOOK_APP_SECRET\s*[=:]\s*["\']([^"\']+)["\']',
                r'GOOGLE_CLIENT_SECRET\s*[=:]\s*["\']([^"\']+)["\']',
                r'GITHUB_TOKEN\s*[=:]\s*["\']([^"\']+)["\']',
                r'SLACK_WEBHOOK\s*[=:]\s*["\']([^"\']+)["\']',
            ],
            'é€šç”¨å¯†é’¥æ¨¡å¼': [
                # åŒ¹é…æ–¹æ³•è°ƒç”¨ä¸­çš„é•¿å­—ç¬¦ä¸²å‚æ•°
                r'\.(?:key|secret|token|password|pwd|appId|appKey|apiKey|secretKey)\s*\(\s*["\']([^"\']{8,})["\']',
                # åŒ¹é…èµ‹å€¼ä¸­çš„é•¿å­—ç¬¦ä¸²å€¼
                r'(?:key|secret|token|password|pwd|appId|appKey|apiKey|secretKey)\s*[=:]\s*["\']([^"\']{8,})["\']',
                # JSONæ ¼å¼çš„å¯†é’¥
                r'"(?:apiKey|secretKey|accessToken|password)"\s*:\s*"([^"]{8,})"',
                r"'(?:apiKey|secretKey|accessToken|password)'\s*:\s*'([^']{8,})'",
            ]
        }
    
    def is_valid_sensitive_info(self, category, text):
        """éªŒè¯æ˜¯å¦ä¸ºçœŸæ­£çš„æ•æ„Ÿä¿¡æ¯"""
        # æ’é™¤å¸¸è§çš„æµ‹è¯•å€¼
        test_values = [
            'test', 'example', 'demo', 'sample', 'dummy', 'null', 'none',
            'password', '1234', '123456', '12345678', 'admin', 'root',
            'localhost', '127.0.0.1', '0.0.0.0', 'example.com',
            'your_', 'my_', 'placeholder', 'changeme', 'secret',
            'api_key', 'token', 'key'
        ]
        
        text_lower = text.lower()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•å€¼
        if any(test in text_lower for test in test_values):
            return False
        
        # æ ¹æ®ç±»åˆ«è¿›è¡Œç‰¹å®šéªŒè¯
        if category == 'IPåœ°å€':
            return self.is_valid_ip(text)
        elif category == 'åŸŸå':
            return self.is_valid_domain(text)
        elif category == 'URLé“¾æ¥':
            return self.is_valid_url(text)
        elif category in ['ç¡¬ç¼–ç å¯†ç ', 'APIå¯†é’¥/AppID', 'Secretå¯†é’¥', 'è®¿é—®ä»¤ç‰Œ', 'åŠ å¯†å¯†é’¥']:
            # å¯¹äºå¯†é’¥ç±»ä¿¡æ¯ï¼Œæ£€æŸ¥é•¿åº¦å’Œå¤æ‚åº¦
            if len(text) < 8:
                return False
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿‡äºç®€å•çš„å€¼
            if re.match(r'^[0-9]+$', text) and len(text) < 16:  # çº¯æ•°å­—ä¸”è¾ƒçŸ­
                return False
            
            if re.match(r'^[a-z]+$', text_lower) and len(text) < 10:  # çº¯å°å†™å­—æ¯ä¸”è¾ƒçŸ­
                return False
        
        return True
    
    def is_valid_ip(self, ip):
        """éªŒè¯IPåœ°å€æ˜¯å¦æœ‰æ•ˆ"""
        parts = ip.split('.')
        if len(parts) != 4:
            return False
        for part in parts:
            if not part.isdigit() or not 0 <= int(part) <= 255:
                return False
        # æ’é™¤ç§æœ‰IPå’Œç‰¹æ®ŠIP
        if (ip.startswith('10.') or 
            ip.startswith('192.168.') or 
            (ip.startswith('172.') and 16 <= int(parts[1]) <= 31) or 
            ip in ['127.0.0.1', '0.0.0.0', '255.255.255.255']):
            return False
        return True
    
    def is_valid_domain(self, domain):
        """éªŒè¯åŸŸåæ˜¯å¦æœ‰æ•ˆ"""
        # ç§»é™¤åè®®éƒ¨åˆ†
        if '://' in domain:
            domain = domain.split('://', 1)[1]
        
        # ç§»é™¤è·¯å¾„å’Œç«¯å£
        domain = domain.split('/')[0].split(':')[0]
        
        # ç®€å•çš„åŸŸåéªŒè¯
        if len(domain) < 3 or len(domain) > 253:
            return False
        if domain.startswith('.') or domain.endswith('.'):
            return False
        if '..' in domain:
            return False
        
        # æ’é™¤å¸¸è§æµ‹è¯•åŸŸå
        test_domains = ['example.com', 'test.com', 'localhost', 'example.org', 
                       'test.org', 'demo.com', 'sample.com', 'localhost.localdomain']
        if any(test in domain.lower() for test in test_domains):
            return False
        
        # éªŒè¯åŸŸåæ ¼å¼
        domain_pattern = r'^[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?)*\.[a-zA-Z]{2,}$'
        return bool(re.match(domain_pattern, domain))
    
    def is_valid_url(self, url):
        """éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ"""
        try:
            result = urlparse(url)
            if not all([result.scheme, result.netloc]):
                return False
            
            # æ’é™¤æµ‹è¯•URL
            test_urls = ['example.com', 'test.com', 'localhost', '127.0.0.1']
            if any(test in result.netloc.lower() for test in test_urls):
                return False
            
            # éªŒè¯å¸¸è§åè®®
            valid_schemes = ['http', 'https', 'ftp', 'ws', 'wss']
            if result.scheme.lower() not in valid_schemes:
                return False
            
            return True
        except:
            return False
    
    def scan_file(self, file_path):
        """æ‰«æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                content = file.read()
                lines = content.split('\n')
                
                findings = []
                
                for line_num, line in enumerate(lines, 1):
                    # è·³è¿‡æ˜æ˜¾çš„æ³¨é‡Šè¡Œï¼ˆé’ˆå¯¹ä¸åŒè¯­è¨€ï¼‰
                    line_stripped = line.strip()
                    comment_patterns = [
                        line_stripped.startswith('//'),
                        line_stripped.startswith('#'),
                        line_stripped.startswith('--'),
                        line_stripped.startswith('/*'),
                        line_stripped.startswith('*'),
                        line_stripped.startswith('"""'),
                        line_stripped.startswith("'''"),
                    ]
                    if any(comment_patterns):
                        continue
                    
                    for category, regex_list in self.patterns.items():
                        for pattern in regex_list:
                            matches = re.finditer(pattern, line, re.IGNORECASE)
                            for match in matches:
                                # æå–åŒ¹é…çš„å†…å®¹
                                if len(match.groups()) > 0:
                                    for group_num, matched_text in enumerate(match.groups(), 1):
                                        if matched_text and self.is_valid_sensitive_info(category, matched_text):
                                            findings.append({
                                                'file': str(file_path),
                                                'line': line_num,
                                                'category': category,
                                                'matched_text': matched_text,
                                                'full_line': line.strip()[:200],
                                                'file_type': file_path.suffix.lower()
                                            })
                                else:
                                    matched_text = match.group()
                                    if self.is_valid_sensitive_info(category, matched_text):
                                        findings.append({
                                            'file': str(file_path),
                                            'line': line_num,
                                            'category': category,
                                            'matched_text': matched_text,
                                            'full_line': line.strip()[:200],
                                            'file_type': file_path.suffix.lower()
                                        })
                
                return findings
                
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return []
    
    def scan_directory(self, directory_path):
        """é€’å½’æ‰«æç›®å½•ä¸­çš„æ‰€æœ‰æ”¯æŒæ–‡ä»¶"""
        all_files = []
        directory_path = Path(directory_path)
        
        if not directory_path.exists():
            print(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
            return []
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
        for file_path in directory_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in self.supported_extensions:
                all_files.append(file_path)
        
        # æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        file_types = {}
        for file_path in all_files:
            ext = file_path.suffix.lower()
            file_types[ext] = file_types.get(ext, 0) + 1
        
        print(f"æ‰¾åˆ° {len(all_files)} ä¸ªæ”¯æŒçš„æ–‡ä»¶ï¼š")
        for ext, count in sorted(file_types.items()):
            print(f"  {ext}: {count} ä¸ª")
        
        all_findings = []
        for file_path in all_files:
            findings = self.scan_file(file_path)
            all_findings.extend(findings)
        
        return all_findings
    
    def generate_csv_report(self, findings, csv_file):
        """ç”ŸæˆCSVæ ¼å¼æ‰«ææŠ¥å‘Š"""
        if not findings:
            print("æœªå‘ç°æ•æ„Ÿä¿¡æ¯ï¼Œä¸ç”ŸæˆCSVæ–‡ä»¶")
            return
        
        # CSVæ–‡ä»¶å¤´
        fieldnames = ['æ–‡ä»¶è·¯å¾„', 'æ–‡ä»¶ç±»å‹', 'è¡Œå·', 'ä¿¡æ¯ç±»å‹', 'åŒ¹é…å†…å®¹', 'å®Œæ•´ä»£ç è¡Œ']
        
        try:
            with open(csv_file, 'w', newline='', encoding='utf-8-sig') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for finding in findings:
                    writer.writerow({
                        'æ–‡ä»¶è·¯å¾„': finding['file'],
                        'æ–‡ä»¶ç±»å‹': finding.get('file_type', 'unknown'),
                        'è¡Œå·': finding['line'],
                        'ä¿¡æ¯ç±»å‹': finding['category'],
                        'åŒ¹é…å†…å®¹': finding['matched_text'],
                        'å®Œæ•´ä»£ç è¡Œ': finding['full_line']
                    })
            
            print(f"CSVæŠ¥å‘Šå·²ä¿å­˜åˆ°: {csv_file}")
            print(f"æ€»å…±å‘ç° {len(findings)} æ¡æ•æ„Ÿä¿¡æ¯")
            
        except Exception as e:
            print(f"ç”ŸæˆCSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def print_summary(self, findings):
        """æ‰“å°æ‰«ææ‘˜è¦"""
        if not findings:
            print("ğŸ‰ æœªå‘ç°æ•æ„Ÿä¿¡æ¯")
            return
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_count = {}
        file_type_count = {}
        
        for finding in findings:
            category = finding['category']
            file_type = finding.get('file_type', 'unknown')
            
            category_count[category] = category_count.get(category, 0) + 1
            file_type_count[file_type] = file_type_count.get(file_type, 0) + 1
        
        print(f"\nğŸ” æ‰«æå®Œæˆï¼å…±å‘ç° {len(findings)} æ¡æ•æ„Ÿä¿¡æ¯ï¼š")
        print(f"\nğŸ“Š æŒ‰ä¿¡æ¯ç±»å‹ç»Ÿè®¡ï¼š")
        for category, count in sorted(category_count.items()):
            print(f"   {category}: {count} æ¡")
        
        print(f"\nğŸ“ æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡ï¼š")
        for file_type, count in sorted(file_type_count.items()):
            print(f"   {file_type}: {count} æ¡")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªå‘ç°ä½œä¸ºç¤ºä¾‹
        print(f"\nğŸ“‹ ç¤ºä¾‹å‘ç°ï¼š")
        for i, finding in enumerate(findings[:5]):
            print(f"   {i+1}. [{finding['category']}] {finding['matched_text']}")

def main():
    parser = argparse.ArgumentParser(description='å¤šè¯­è¨€æ–‡ä»¶æ•æ„Ÿä¿¡æ¯æ‰«æå·¥å…·')
    parser.add_argument('directory', help='è¦æ‰«æçš„ç›®å½•è·¯å¾„')
    parser.add_argument('-o', '--output', default='sensitive_info_report.csv', 
                       help='CSVæŠ¥å‘Šè¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: sensitive_info_report.csv)')
    parser.add_argument('-v', '--verbose', action='store_true', help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    parser.add_argument('--extensions', help='æŒ‡å®šé¢å¤–çš„æ–‡ä»¶æ‰©å±•åï¼Œç”¨é€—å·åˆ†éš”ï¼ˆä¾‹å¦‚ï¼š.vue,.sass,.lessï¼‰')
    
    args = parser.parse_args()
    
    scanner = SensitiveInfoScanner()
    
    # æ·»åŠ ç”¨æˆ·æŒ‡å®šçš„æ‰©å±•å
    if args.extensions:
        extra_extensions = set(ext.strip().lower() for ext in args.extensions.split(','))
        scanner.supported_extensions.update(extra_extensions)
        print(f"æ·»åŠ äº†é¢å¤–çš„æ–‡ä»¶æ‰©å±•å: {', '.join(extra_extensions)}")
    
    if args.verbose:
        print(f"å¼€å§‹æ‰«æç›®å½•: {args.directory}")
        print(f"æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {len(scanner.supported_extensions)} ç§")
    
    findings = scanner.scan_directory(args.directory)
    
    scanner.print_summary(findings)
    scanner.generate_csv_report(findings, args.output)

if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œï¼Œä½¿ç”¨ç¤ºä¾‹
    if len(os.sys.argv) == 1:
        directory = input("è¯·è¾“å…¥è¦æ‰«æçš„ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰: ").strip()
        if not directory:
            directory = "."
        
        output_file = input("è¯·è¾“å…¥CSVæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: sensitive_info_report.csvï¼‰: ").strip()
        if not output_file:
            output_file = "sensitive_info_report.csv"
        
        extra_extensions = input("è¯·è¾“å…¥é¢å¤–çš„æ–‡ä»¶æ‰©å±•åï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼‰: ").strip()
        
        scanner = SensitiveInfoScanner()
        
        if extra_extensions:
            extra_extensions_set = set(ext.strip().lower() for ext in extra_extensions.split(','))
            scanner.supported_extensions.update(extra_extensions_set)
            print(f"æ·»åŠ äº†é¢å¤–çš„æ–‡ä»¶æ‰©å±•å: {', '.join(extra_extensions_set)}")
        
        findings = scanner.scan_directory(directory)
        scanner.print_summary(findings)
        scanner.generate_csv_report(findings, output_file)
    else:
        main()
